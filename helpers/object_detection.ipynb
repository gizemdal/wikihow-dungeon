{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelperFunctions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjjkbiDnfzLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article1 = {\n",
        "    \"title\": \"How to Request a New Article Topic Be Written on wikiHow\",\n",
        "    \"url\": \"https://www.wikihow.com/Request-a-New-Article-Topic-Be-Written-on-wikiHow\",\n",
        "    \"title_description\": \"At wikiHow, you can suggest a topic that has not yet been covered. This article will tell you how.\",\n",
        "    \"category_hierarchy\": [],\n",
        "    \"method/part\": [],\n",
        "    \"steps\": [\n",
        "        [\n",
        "            \"Review how to refrain from making unhelpful Suggested Topics on wikiHow\",\n",
        "            \"\\nDo not post a suggestion more than once.\\nDo not post a suggestion too similar to an existing article title.\\nA topic that either makes no sense or violates wikiHow's rules will be deleted.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Search wikiHow\",\n",
        "            \" Duplicate suggestions will eventually be merged or deleted.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Click on the \\\"Help Us\\\" button in the top right corner of any wikiHow page\",\n",
        "            \" Then click on the Request a New Article link in the drop-down box that opens.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Enter a title according to the Title policy\",\n",
        "            \"\\nBe clear, concise and specific.\\nWith the exception of small prepositions (the, a, an, etc.), coordinate conjunctions, and preposition (except for when used as part of a verb), all other words should contain at least one capital letter at the beginning.\\nDo not type \\\"How to\\\" as this is automatically added.\\nDon't use possessive words. Words such as mine, my, ours, his, hers, etc can make the writer think he is writing the article just for you. wikiHow articles are for everyone and should be specific in description, but not specific to certain people.\\nUse proper capitalization for products, companies, location, etc. Examples are iPhone, PC, BBC, USA, and Myspace.\\nStart your request with an action verb, such as \\\"Grow\\\", \\\"Make\\\", \\\"Answer\\\", etc.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Categorize your suggestion to help others locate your topic\",\n",
        "            \"\\nChoose a category from the drop down menu. For example, recipes belong in the \\\"Food and Entertaining\\\" category and any fashion would be under the \\\"Personal Care and Style\\\" category.\\nIf a category does not fit your suggestion, choose the \\\"Other\\\" category.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Determine if you want to be emailed when your article is written\",\n",
        "            \"\\nIf you want wikiHow to email you, select the box labelled \\\"E-mail me when my how-to is written:\\\"\\nIf your settings allow editors to contact you via email, your address that was applied, will automatically be used and automatically typed into the box upon entry.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Look at the reCAPTCHA image\",\n",
        "            \" Type it into the box directly below the image.\"\n",
        "        ],\n",
        "        [\n",
        "            \"Click the \\\"Submit\\\" button, when you are finished\",\n",
        "            \"\"\n",
        "        ],\n",
        "        [\n",
        "            \"Be patient\",\n",
        "            \" Suggestions may take a while to be accepted by those users who have certain rights and time to be finally answered.\"\n",
        "        ]\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpiRxCcSx1ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "defc7476-2b90-4fee-8d33-ee229df57b6b"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fik7Fit8gAi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk, string\n",
        "\n",
        "from nltk import RegexpParser\n",
        "from nltk.tree import Tree\n",
        "\n",
        "def is_imperative(tagged_sent):\n",
        "    # if the sentence is not a question...\n",
        "    if tagged_sent[-1][0] != \"?\":\n",
        "        # catches simple imperatives, e.g. \"Open the pod bay doors, HAL!\"\n",
        "        if tagged_sent[0][1] == \"VB\" or tagged_sent[0][1] == \"MD\":\n",
        "            return True\n",
        "\n",
        "        # catches imperative sentences starting with words like 'please', 'you',...\n",
        "        # E.g. \"Dave, stop.\", \"Just take a stress pill and think things over.\"\n",
        "        else:\n",
        "            chunk = get_chunks(tagged_sent)\n",
        "            # check if the first chunk of the sentence is a VB-Phrase\n",
        "            if type(chunk[0]) is Tree and chunk[0].label() == \"VB-Phrase\":\n",
        "                return True\n",
        "\n",
        "    # Questions can be imperatives too, let's check if this one is\n",
        "    else:\n",
        "        # check if sentence contains the word 'please'\n",
        "        pls = len([w for w in tagged_sent if w[0].lower() == \"please\"]) > 0\n",
        "        # catches requests disguised as questions\n",
        "        # e.g. \"Open the doors, HAL, please?\"\n",
        "        chunk = get_chunks(tagged_sent)\n",
        "        if pls and (tagged_sent[0][1] == \"VB\" or tagged_sent[0][1] == \"MD\"):\n",
        "            return True\n",
        "\n",
        "        # catches imperatives ending with a Question tag\n",
        "        # and starting with a verb in base form, e.g. \"Stop it, will you?\"\n",
        "        elif type(chunk[-1]) is Tree and chunk[-1].label() == \"Q-Tag\":\n",
        "            if (chunk[0][1] == \"VB\" or\n",
        "                (type(chunk[0]) is Tree and chunk[0].label() == \"VB-Phrase\")):\n",
        "                return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# chunks the sentence into grammatical phrases based on its POS-tags\n",
        "def get_chunks(tagged_sent):\n",
        "    chunkgram = r\"\"\"VB-Phrase: {<DT><,>*<VB>}\n",
        "                    VB-Phrase: {<RB><VB>}\n",
        "                    VB-Phrase: {<UH><,>*<VB>}\n",
        "                    VB-Phrase: {<UH><,><VBP>}\n",
        "                    VB-Phrase: {<PRP><VB>}\n",
        "                    VB-Phrase: {<NN.?>+<,>*<VB>}\n",
        "                    Q-Tag: {<,><MD><RB>*<PRP><.>*}\"\"\"\n",
        "    chunkparser = RegexpParser(chunkgram)\n",
        "    return chunkparser.parse(tagged_sent)\n",
        "\n",
        "# Tokenizer that I implemented from CIS421\n",
        "def tokenize(text):\n",
        "    tokens = []\n",
        "    words = text.split(' ')\n",
        "    for word in words:\n",
        "        if len(word) == 0:\n",
        "            continue\n",
        "        w = []\n",
        "        for c in word:\n",
        "            if c in string.punctuation:\n",
        "                if len(w) != 0:\n",
        "                    tokens.append(''.join(w))\n",
        "                    w = []\n",
        "                tokens.append(c)\n",
        "            else:\n",
        "                if c not in string.whitespace:\n",
        "                    w.append(c)\n",
        "        if len(w) != 0:\n",
        "            tokens.append(''.join(w))\n",
        "    return tokens\n",
        "\n",
        "# text = 'Wash your hands frequently.'\n",
        "# tags = nltk.pos_tag(tokenize(text))\n",
        "# print(tags)\n",
        "# print(is_imperative(tags))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE8BWMiYsoW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# refered from https://stackoverflow.com/questions/41051125/turning-a-sentence-from-first-to-second-person\n",
        "\n",
        "forms = {\"am\" : \"are\", \"are\" : \"am\", 'i' : 'you', 'my' : 'your', 'me' : 'you', 'mine' : 'yours', 'you' : 'I', \n",
        "'your' : 'my', 'yours' : 'mine'}\n",
        "\n",
        "def translate(text):\n",
        "  # print(text)\n",
        "  result = text\n",
        "  for word in text.split():\n",
        "    # print(word)\n",
        "    if word.lower() in forms: \n",
        "      result = result.replace(word, forms[word.lower()])\n",
        "      # print(result)\n",
        "  # print(result)\n",
        "  return result\n",
        "\n",
        "def changePerson(text):\n",
        "  result = \"\"\n",
        "  tags = nltk.pos_tag(tokenize(text))\n",
        "  isImp = is_imperative(tags)\n",
        "\n",
        "  if isImp:\n",
        "    result = \"You \" + text\n",
        "  else:\n",
        "    result = translate(text)\n",
        "  return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i936au83mSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "25d3e607-7106-4ca2-d7b0-12d0d1f0d450"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ajzj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wash your hands'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzosXVnA4Ssp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ca6dfe9-1479-4004-f0d7-6cfa99d50199"
      },
      "source": [
        "def identifyObjects(text):\n",
        "  tags = nltk.pos_tag(tokenize(text))\n",
        "  objects = []\n",
        "  for t in tags:\n",
        "    if t[1]==\"NN\":\n",
        "      objects.append(t[0])\n",
        "  return objects\n",
        "# identifyObjects(\"You have a dog and a harness\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog', 'harness']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYnH-euZL3TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}