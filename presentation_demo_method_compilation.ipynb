{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "presentation_demo_method_compilation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V00oq1Gijyfp",
        "colab_type": "text"
      },
      "source": [
        "Add necessary imports here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0bjJ3ameX5",
        "colab_type": "code",
        "outputId": "5b24de03-2251-4879-d6bb-7e1dd380061b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "!pip3 install pymagnitude\n",
        "!wget http://magnitude.plasticity.ai/glove/heavy/glove.6B.300d.magnitude\n",
        "\n",
        "from pymagnitude import *\n",
        "vectors = Magnitude(\"glove.6B.300d.magnitude\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymagnitude in /usr/local/lib/python3.6/dist-packages (0.1.120)\n",
            "--2020-04-22 16:39:56--  http://magnitude.plasticity.ai/glove/heavy/glove.6B.300d.magnitude\n",
            "Resolving magnitude.plasticity.ai (magnitude.plasticity.ai)... 52.216.106.179\n",
            "Connecting to magnitude.plasticity.ai (magnitude.plasticity.ai)|52.216.106.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1384890368 (1.3G) [binary/octet-stream]\n",
            "Saving to: ‘glove.6B.300d.magnitude.2’\n",
            "\n",
            "glove.6B.300d.magni 100%[===================>]   1.29G  47.8MB/s    in 29s     \n",
            "\n",
            "2020-04-22 16:40:25 (45.9 MB/s) - ‘glove.6B.300d.magnitude.2’ saved [1384890368/1384890368]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxqw4tkIjdZm",
        "colab_type": "code",
        "outputId": "6205cc56-3e41-47a5-b870-52a0e5ba8610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import string\n",
        "import nltk, string, os, json\n",
        "\n",
        "from nltk import RegexpParser\n",
        "from nltk.tree import Tree\n",
        "import random\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7n_dq__imjX",
        "colab_type": "code",
        "outputId": "3f0915b8-081a-4992-ade7-ce081b27f63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "!mkdir encoder\n",
        "!curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘encoder’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0  44.7M      0  0:00:03  0:00:03 --:--:-- 44.7M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2yupugm-xc",
        "colab_type": "text"
      },
      "source": [
        "Set up models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WslCK9eniuYl",
        "colab_type": "code",
        "outputId": "348eff52-88a5-4db9-bccd-4057f53f2b17",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Include models.py in the directory\n",
        "files.upload()\n",
        "from models import InferSent\n",
        "model_version = 1\n",
        "MODEL_PATH = \"encoder/infersent%s.pkl\" % model_version\n",
        "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
        "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
        "model = InferSent(params_model)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a7b63124-d72d-4cf6-b91b-590d70bf23f6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a7b63124-d72d-4cf6-b91b-590d70bf23f6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3IJTj70kZzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.set_w2v_path('drive/Shared drives/CIS 700 Project/GloVe/glove.840B.300d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuMzIoOYkc6R",
        "colab_type": "code",
        "outputId": "fadeaf69-786d-45fa-9b12-36cad2f96c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "model.build_vocab_k_words(K=100000)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnhRWtBnC-K",
        "colab_type": "text"
      },
      "source": [
        "Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5O17vcjlNY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59BNuFhsll1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_command(user_command, known_commands):\n",
        "\n",
        "  sim1 = find_most_similar_command(user_command, known_commands)\n",
        "  sim = []\n",
        "  for k in known_commands:\n",
        "    sim.append(cosine(model.encode(user_command)[0], model.encode(k)[0]))\n",
        "  # sim = [float(i)/sum(sim) for i in sim]\n",
        "  for i in range(len(sim)):\n",
        "    sim[i] += sim1[i]\n",
        "  idx = sim.index(max(sim))\n",
        "  #print(sim)\n",
        "  #print(idx)\n",
        "  return known_commands[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oZ7xehPlmKN",
        "colab_type": "text"
      },
      "source": [
        "Add necessary dictionaries/lists and parsing methods here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGn2MLXhljpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_article(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        s = [] # steps - list of tuples (method_number, step text)\n",
        "        d = {} # descriptions - Description dictionary step text -> description\n",
        "        m = [] # methods\n",
        "        data_json = json.load(f)\n",
        "        title = data_json['title']\n",
        "        if title != None:\n",
        "        # Get the steps\n",
        "            if len(data_json['method/part']) > 0:\n",
        "                methods = data_json['method/part']\n",
        "                for method in methods:\n",
        "                    all_steps = [(method['name'], step['headline']) for step in method['steps']]\n",
        "                    s += all_steps\n",
        "                    m += method['name']\n",
        "                    all_descs = dict(zip([step['headline'] for step in method['steps']], [step['description'] for step in method['steps']]))\n",
        "                    d.update(all_descs)      \n",
        "            else:\n",
        "              print(filename)\n",
        "               # s = [(None, step[0]) for step in data_json['steps']]\n",
        "               # d = dict(zip([step[0] for step in data_json['steps']], [step[1] for step in data_json['steps']]))\n",
        "        else:\n",
        "            print('Article has no title!')\n",
        "        return s, d, m, title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycT2eU3SnKJy",
        "colab_type": "text"
      },
      "source": [
        "NLTK Package Downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0xYG8mDXoN",
        "colab_type": "code",
        "outputId": "01010ecf-3abd-4f55-a462-a30976e0ec8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "# download averaged_perceptron_tagger, wordnet\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tLcCfm4l-A-",
        "colab_type": "text"
      },
      "source": [
        "Add NLTK POS-tagging and tokenizer here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_CsP9T2mDP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source: https://stackoverflow.com/questions/29473169/approach-for-identifying-whether-a-sentence-includes-an-imperative-within-it?fbclid=IwAR1kGWHvo0M1sSMMXl4Rv4PJ-dhRchEABc83JQpAqotQnFqY3uUBD0jAMAU\n",
        "\n",
        "def is_imperative(tagged_sent):\n",
        "    # if the sentence is not a question...\n",
        "    if tagged_sent[-1][0] != \"?\":\n",
        "         #catches simple imperatives, e.g. \"Open the pod bay doors, HAL!\"\n",
        "        \n",
        "        if tagged_sent[0][1] == \"VB\" or tagged_sent[0][1] == \"MD\":\n",
        "            return True\n",
        "        \n",
        "        # catches imperative sentences starting with words like 'please', 'you',...\n",
        "        # E.g. \"Dave, stop.\", \"Just take a stress pill and think things over.\"\n",
        "        else:\n",
        "          # check if the first word has a verb synonym\n",
        "          synonyms = [syns.name() for syns in wordnet.synsets(tagged_sent[0][0])]\n",
        "          # split the synonyms array into two: more related synonyms should appear earlier\n",
        "          # Follow a heuristic such that if a verb synonym doesn't appear in the first half\n",
        "          # then this word is likely more often used as a noun\n",
        "          synonyms = synonyms[0:len(synonyms)//2]\n",
        "          for synonym in synonyms:\n",
        "            # if there is a verb written the same way as the first token, return true\n",
        "            splitted = synonym.split('.')\n",
        "            if splitted[1] == 'v':\n",
        "              if splitted[0] == tagged_sent[0][0].lower():\n",
        "                return True\n",
        "          #chunk = get_chunks(tagged_sent)\n",
        "          # check if the first chunk of the sentence is a VB-Phrase\n",
        "          #if type(chunk[0]) is Tree and chunk[0].label() == \"VB-Phrase\":\n",
        "              #return True\n",
        "    # For the sake of our game, consider the questions as non-imperative  \n",
        "    return False\n",
        "\n",
        "# chunks the sentence into grammatical phrases based on its POS-tags\n",
        "def get_chunks(tagged_sent):\n",
        "    chunkgram = r\"\"\"VB-Phrase: {<DT><,>*<VB>}\n",
        "                    VB-Phrase: {<RB><VB>}\n",
        "                    VB-Phrase: {<UH><,>*<VB>}\n",
        "                    VB-Phrase: {<UH><,><VBP>}\n",
        "                    VB-Phrase: {<PRP><VB>}\n",
        "                    VB-Phrase: {<NN.?>+<,>*<VB>}\n",
        "                    Q-Tag: {<,><MD><RB>*<PRP><.>*}\"\"\"\n",
        "    chunkparser = RegexpParser(chunkgram)\n",
        "    return chunkparser.parse(tagged_sent)\n",
        "\n",
        "# Tokenizer that I implemented from CIS421\n",
        "def tokenize(text):\n",
        "    tokens = []\n",
        "    words = text.split(' ')\n",
        "    for word in words:\n",
        "        if len(word) == 0:\n",
        "            continue\n",
        "        w = []\n",
        "        for c in word:\n",
        "            if c in string.punctuation:\n",
        "              if c == '\\'':\n",
        "                w.append(c)\n",
        "              else:\n",
        "                  if len(w) != 0:\n",
        "                      tokens.append(''.join(w))\n",
        "                      w = []\n",
        "                  tokens.append(c)\n",
        "            else:\n",
        "                if c not in string.whitespace:\n",
        "                    w.append(c)\n",
        "        if len(w) != 0:\n",
        "            tokens.append(''.join(w))\n",
        "    return tokens\n",
        "\n",
        "def imperative_check(text):\n",
        "  # First tokenize the step headline\n",
        "  tokens = tokenize(text)\n",
        "  # Get the POS-tags\n",
        "  tags = nltk.pos_tag(tokens)\n",
        "  # Check if imperative\n",
        "  imperative = is_imperative(tags)\n",
        "  \n",
        "  return imperative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkblXFACmbI-",
        "colab_type": "text"
      },
      "source": [
        "Add similarity check functions here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaGYou_ums8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get vector for the given sentence\n",
        "def construct_sentence_vector(command, vectors):\n",
        "  sentence_vector = np.zeros(shape=(vectors.dim,))\n",
        "  for word in command.split():\n",
        "    word_vector = vectors.query(word)\n",
        "    sentence_vector += word_vector\n",
        "  sentence_vector = sentence_vector / len(command.split())\n",
        "  return sentence_vector\n",
        "\n",
        "def construct_sentence_vector(command):\n",
        "  sentence_vector = np.zeros(shape=(vectors.dim,))\n",
        "  cnt = 0\n",
        "  for word in command.split():\n",
        "    word_vector = vectors.query(word)\n",
        "    # TODO - Do something\n",
        "    sentence_vector = sentence_vector + word_vector\n",
        "    cnt+=1\n",
        "  sentence_vector = sentence_vector/cnt\n",
        "  return sentence_vector\n",
        "\n",
        "#compare items in the list to the article_field. for instance, if you want to find the most similar titles\n",
        "#article_field should be the title, and list should be a list of titles you want to find the most similar out of\n",
        "def find_most_similar(article_field, list, vectors):\n",
        "  vecs = {}\n",
        "  max_sim = 0\n",
        "  most_sim = list[0]\n",
        "  vector_1 = construct_sentence_vector(article_field, vectors)\n",
        "  for obj in list:\n",
        "    vecs[obj] = construct_sentence_vector(obj, vectors)\n",
        "  for obj in vecs:\n",
        "    sim = vectors.similarity(vecs[obj], vector_1)\n",
        "    if sim > max_sim:\n",
        "      most_sim = obj\n",
        "      max_sim = sim\n",
        "  return most_sim\n",
        "\n",
        "def find_most_similar_command(user_command, known_commands):\n",
        "  # TODO - Do something\n",
        "  user_sent = construct_sentence_vector(user_command)\n",
        "  known_sent = []\n",
        "  for command in known_commands:\n",
        "    known_sent.append(construct_sentence_vector(command))\n",
        "  #ans = vectors.similarity(user_sent, known_sent) \n",
        "  known_sent = np.array(known_sent)\n",
        "  sim = vectors.similarity(user_sent, known_sent).tolist()\n",
        "  # ind = sim.index(max(sim))\n",
        "  # print(sim)\n",
        "  # return known_commands[ind]\n",
        "  return sim\n",
        "\n",
        "#get the top k most similar\n",
        "def top_k_similar(article_field, list, vectors, k):\n",
        "  top = []\n",
        "  for i in range(k):\n",
        "    most_sim = find_most_similar(article_field, list, vectors)\n",
        "    top.append(most_sim)\n",
        "    list.remove(most_sim)\n",
        "  return top\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp_ODobWo8FN",
        "colab_type": "text"
      },
      "source": [
        "Add object identifier & 3rd person sentence formation here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADEpXL8QpB4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# refered from https://stackoverflow.com/questions/41051125/turning-a-sentence-from-first-to-second-person\n",
        "\n",
        "forms = {\"am\" : \"are\", 'i' : 'you', 'my' : 'your', 'me' : 'you', 'mine' : 'yours'} #'you' : 'I', 'your' : 'my', 'yours' : 'mine', \"are\" : \"am\"}\n",
        "\n",
        "def translate(text):\n",
        "  # print(text)\n",
        "  if '\"' in text:\n",
        "    result = \"\"\n",
        "    _text = text.split('\"')\n",
        "    l = len(_text)\n",
        "    for i in range(l):\n",
        "      if i%2==0:\n",
        "        result += _text[i]\n",
        "        for word in _text[i].split():\n",
        "          # print(word)\n",
        "          if word.lower() in forms: \n",
        "            result = result.replace(word, forms[word.lower()])\n",
        "      else:\n",
        "        s = '\"' + _text[i] + '\"'\n",
        "        result+= s\n",
        "    return result\n",
        "\n",
        "  result = text\n",
        "  for word in text.split():\n",
        "    # print(word)\n",
        "    if word.lower() in forms: \n",
        "      result = result.replace(word, forms[word.lower()])\n",
        "      # print(result)\n",
        "  # print(result)\n",
        "  return result\n",
        "\n",
        "def changePerson(text):\n",
        "  result = \"\"\n",
        "  sentences = text.split(\".\")\n",
        "  # print(text)\n",
        "  for _s in sentences:\n",
        "    s = _s.strip()\n",
        "    if s==\"\":\n",
        "      continue\n",
        "    tags = nltk.pos_tag(tokenize(s))\n",
        "    isImp = is_imperative(tags)\n",
        "\n",
        "    r = \"\"\n",
        "    if isImp:\n",
        "      if s[0] == ' ' or s[0] == '\\n':\n",
        "        r += \"You \" + s[1].lower() + s[2:]\n",
        "      else:\n",
        "        r += \"You \" + s[0].lower() + s[1:]\n",
        "    else:\n",
        "      r = s\n",
        "    result += translate(r)\n",
        "    result+='.\\n'\n",
        "  return result\n",
        "\n",
        "def identifyObjects(text):\n",
        "  tags = nltk.pos_tag(tokenize(text))\n",
        "  objects = []\n",
        "  for t in tags:\n",
        "    if t[1]==\"NN\":\n",
        "      objects.append(t[0])\n",
        "  return objects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVlVmf0lnWN7",
        "colab_type": "text"
      },
      "source": [
        "Description Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZVx1m7mN6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_description(title):\n",
        "  DATA = \"\"\n",
        "  tit=\"\"\n",
        "  if title.split()[0].lower()==\"how\" and title.split()[1].lower()==\"to\":\n",
        "    tit += \"You want \"\n",
        "    tit += \" \".join(title.split()[1:])\n",
        "  # else:\n",
        "  \n",
        "  objects = identifyObjects(title)\n",
        "  if len(objects) == 0:\n",
        "    DATA = tit\n",
        "  else:\n",
        "    DATA += (tit + '\\n')\n",
        "  # print(objects)\n",
        "  if len(objects)==1:\n",
        "    s = \"You have a \" + objects[0] + \"\\n\"\n",
        "    DATA += s\n",
        "  elif len(objects)>1:\n",
        "    ob = ''\n",
        "    ob += ', '.join(objects)\n",
        "    s = \"You have \" + ob + '\\n'\n",
        "    DATA += s\n",
        "  \n",
        "  print(DATA)\n",
        "\n",
        "def get_description_title(title):\n",
        "  tit=\"\"\n",
        "  title = title.lower()\n",
        "  if title.split()[0].lower()==\"how\" and title.split()[1].lower()==\"to\":\n",
        "    tit += \"You want \"\n",
        "    tit += \" \".join(title.split()[1:])\n",
        "  print(tit)\n",
        "\n",
        "def get_step_description_game(step, description):\n",
        "  des = description[step]\n",
        "  # print(des)\n",
        "  if(des==\"\"):\n",
        "    return\n",
        "  d = changePerson(des)\n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emb5e4PbkgAq",
        "colab_type": "text"
      },
      "source": [
        "Once imports and functions are done, upload a JSON file, get its name and parse it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrx0bPyhkls_",
        "colab_type": "code",
        "outputId": "7d535ae8-1834-47a8-8996-a8cb81b50c49",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-77ee5960-3c27-416e-8d51-f67433543b2f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-77ee5960-3c27-416e-8d51-f67433543b2f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 3895.json to 3895.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QHzl_kv-htb",
        "colab_type": "code",
        "outputId": "66927021-6e71-40f1-ebf1-826a80f3c3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "try:\n",
        "  file_name = list(uploaded.keys())[0]\n",
        "  print(file_name)\n",
        "except:\n",
        "  f = open('/content/3029.json')\n",
        "  file_name = f.name.split('/')\n",
        "  file_name = file_name[len(file_name) - 1]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3895.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp1JD5snlA01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trim_beginning_punctuation(sentence):\n",
        "  to_return = ''\n",
        "  letter_seen = False\n",
        "  for c in sentence:\n",
        "    if c in string.punctuation or c in string.whitespace:\n",
        "      if letter_seen:\n",
        "        to_return += c\n",
        "    else:\n",
        "      if c in string.ascii_letters:\n",
        "        if not letter_seen:\n",
        "          letter_seen = True\n",
        "        to_return += c\n",
        "  return to_return\n",
        "\n",
        "def milestone_1_results(filename, include_desc):\n",
        "  # include_desc -> Do you want to include imperative description sentences as game steps?\n",
        "  steps, descriptions, method_names, title = get_article(filename)\n",
        "  # print the title of the article\n",
        "  #print('Title: ' + title)\n",
        "  print(title)\n",
        "  # Once the necessary fields are filled, find imperatives\n",
        "  imperatives = []\n",
        "\n",
        "  for step in steps:\n",
        "    # First split the headline into sentences\n",
        "    headline_sentences = step[1].split('.')\n",
        "    for headline in headline_sentences:\n",
        "      trimmed_headline = trim_beginning_punctuation(headline)\n",
        "      trimmed_headline = trimmed_headline.replace('\\n', '')\n",
        "      if len(trimmed_headline) == 0:\n",
        "          continue\n",
        "      if imperative_check(trimmed_headline):\n",
        "        imperatives.append(trimmed_headline)\n",
        "        break # No two imperatives from the same headline are added.\n",
        "    if include_desc:\n",
        "      description = descriptions[step[1]]\n",
        "      # Split the description paragraph into sentences\n",
        "      sentences = description.split('.')\n",
        "      for sentence in sentences:\n",
        "        trimmed_sentence = trim_beginning_punctuation(sentence)\n",
        "        trimmed_sentence = trimmed_sentence.replace('\\n', '')\n",
        "        if len(trimmed_sentence) == 0:\n",
        "          continue\n",
        "        if imperative_check(trimmed_sentence):\n",
        "          imperatives.append(trimmed_sentence)\n",
        "          break # No two imperatives from the same description are added. !!! REMOVE THIS IF you want multiple imperatives\n",
        "\n",
        "    \n",
        "  # Once imperatives are found, print them and turn them into 3rd person\n",
        "  #print('\\nList of Imperatives:\\n')\n",
        "  #for imp in imperatives:\n",
        "    #print(imp)\n",
        "    \n",
        "  #third_person = [changePerson(imperative) for imperative in imperatives]\n",
        "  return imperatives, title, descriptions\n",
        "\n",
        "  # Print the 3rd person sentences in order\n",
        "  #print('\\nImperatives Turned Into 3rd Person:\\n')\n",
        "  #for third in third_person:\n",
        "    #print(third)\n",
        "  \n",
        "  # # Find 5 similar articles to this article given the title\n",
        "  # k = 5\n",
        "\n",
        "  # # Make sure that the folder new_wikihow_1000 is in the drive - that's where we have all the data\n",
        "  # file_path = '/content/drive/My Drive/Colab Notebooks/new_wikihow_1000'\n",
        "  # all_files = os.listdir(file_path)\n",
        "  # files_and_titles = {} # title -> filename dictionary\n",
        "  # idx = 0\n",
        "  # for data in all_files:\n",
        "  #   if idx >= 100: # for now the number of files to read is limited to 100\n",
        "  #     break\n",
        "  #   with open(file_path + '/' + data, \"r\") as f:\n",
        "  #     data_json = json.load(f)\n",
        "  #     t = data_json['title']\n",
        "  #     # Skip articles with no title\n",
        "  #     if t == None:\n",
        "  #       continue\n",
        "  #     files_and_titles[t] = data\n",
        "  #     idx += 1\n",
        "  \n",
        "  # # Once we have file titles, pass them as a list to top_k_similar()\n",
        "  # k_similar = top_k_similar(title, list(files_and_titles.keys()), vectors, k)\n",
        "  \n",
        "  # # Print the top k similar article titles and the corresponding json file name\n",
        "  # print('\\nTop ' + str(k) + ' Similar Article Titles:\\n')\n",
        "  # for similar in k_similar:\n",
        "  #   print('Title: ' + similar + ', Filename: ' + files_and_titles[similar])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIAWaWnUnmbz",
        "colab_type": "text"
      },
      "source": [
        "Start extracting from article here:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt2m3sCSnmEB",
        "colab_type": "code",
        "outputId": "090a9391-8cc1-4c4d-dd5a-c8a7bd174c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Send True to include descriptions as well!\n",
        "known_commands, title, descriptions = milestone_1_results(file_name, False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How to Kiss a Boy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZjDqIVdkje_",
        "colab_type": "code",
        "outputId": "225b2594-91ad-4cbc-a70e-44601c8fd712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "try:\n",
        "  embeddings = model.encode(known_commands, bsize=128, tokenize=False, verbose=True)\n",
        "  print('nb sentences encoded : {0}'.format(len(embeddings)))\n",
        "except:\n",
        "  print('This article has no imperatives!')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb words kept : 184/192 (95.8%)\n",
            "Speed : 36.1 sentences/s (cpu mode, bsize=128)\n",
            "nb sentences encoded : 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfUpGmwxrex5",
        "colab_type": "text"
      },
      "source": [
        "Method for choice picking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RiMu5X2rdxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pick_choices(current_step, commands):\n",
        "  if len(commands) - 1 == current_step:\n",
        "    return None, None\n",
        "  elif len(commands) - 2 == current_step:\n",
        "    # Can only pick one wrong choice\n",
        "    return len(commands) - 1, None\n",
        "  else:\n",
        "    # pick 2 that are not in steps_seen\n",
        "    options_first = [num for num in range(current_step + 1, len(commands))]\n",
        "    first = random.choice(options_first)\n",
        "    options_second = [num for num in range(current_step + 1, len(commands)) if num != first]\n",
        "    second = random.choice(options_second)\n",
        "    return first,second"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DXUy-ps8pLT",
        "colab_type": "text"
      },
      "source": [
        "Wrong choice warnings: pick one of these if the player picks a wrong option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOmbyXaK9IsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_warning = ['Whoa! You should not do that yet.', 'Umm.. maybe you should not do that now.', 'That could work in an ideal world, but that is not what we have here. Try again please!', 'No no no...']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrVRSszjpS_R",
        "colab_type": "text"
      },
      "source": [
        "Start the game here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIPXouHvpZaC",
        "colab_type": "code",
        "outputId": "477eb381-0609-43c9-801a-c4b7775adcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "current_step = 0\n",
        "steps_seen = []\n",
        "end_game = False\n",
        "print('Game: ' + title + '\\n')\n",
        "get_description_title(title)\n",
        "while not end_game:\n",
        "  if current_step == len(known_commands):\n",
        "    end_game = True\n",
        "    print('You reached the end of the game')\n",
        "  else:\n",
        "    if current_step == 0:\n",
        "      print('What do you do first?')\n",
        "    else:\n",
        "      print('What do you do next?')\n",
        "    print('You:')\n",
        "    first, second = pick_choices(current_step, known_commands)\n",
        "    choices = []\n",
        "    # if wrong choices exist\n",
        "    if first:\n",
        "      if second:\n",
        "        choices.append(known_commands[second])\n",
        "      choices.append(known_commands[first])\n",
        "    choices.append(known_commands[current_step])\n",
        "    correct_choice = known_commands[current_step] # this is the correct choice\n",
        "    random.shuffle(choices) # shuffle the order of choices\n",
        "    for choice in choices:\n",
        "      print('\\t' + choice.lower())\n",
        "    correct_found = False\n",
        "    while not correct_found:\n",
        "      user_pick = input('>')\n",
        "      if user_pick.lower() == 'quit':\n",
        "        correct_found = True\n",
        "        end_game = True\n",
        "        print('You ended the game.')\n",
        "        continue\n",
        "      # Check if what the user picked is correct\n",
        "      most_similar = find_similar_command(user_pick, known_commands)\n",
        "      if most_similar.lower() == correct_choice.lower():\n",
        "        # Correct!\n",
        "        current_step += 1\n",
        "        correct_found = True\n",
        "        # Get description\n",
        "        print(get_step_description_game(correct_choice, descriptions))\n",
        "      else:\n",
        "        print(random.choice(wrong_warning))\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: How to Kiss a Boy\n",
            "\n",
            "You want to kiss a boy\n",
            "What do you do first?\n",
            "You:\n",
            "\twait for a lull in the conversation\n",
            "\tput your hands to good use while you're kissing\n",
            "\texplore other ways to kiss him\n",
            ">wait for a lull in conversation\n",
            "Timing a kiss just right can be hard! It's usually best to wait for a natural lull in the conversation to lean in for a snuggle or a kiss.\n",
            "You let the conversation dwindle on its own, but stay close to him.\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\tlock eyes with him\n",
            "\tkeep your body language positive and open\n",
            "\tuse your tongue sparingly\n",
            ">use your tongue sparingly\n",
            "Umm.. maybe you should not do that now.\n",
            ">lock eyes with him\n",
            "You be bold about making eye contact and do it often, especially right before you're about to go in for the kiss.\n",
            "Not only does looking deeply into his eyes feel romantic, but it's easier to make a genuine connection when you're looking into each other's eyes.\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\tlean in, close your eyes, and tilt your head to the side\n",
            "\tkeep your body language positive and open\n",
            "\ttest the waters by kissing him on the cheek\n",
            ">lean in close your eyes and tilt your head\n",
            "No no no...\n",
            ">kiss him on the cheek\n",
            "If you're unsure about how he'll react to a regular kiss on the mouth, you can always give him a kiss on the cheek first.\n",
            "You can give him a quick peck after he says something sweet, or move in slow and prolong the kiss for a few seconds to show him that you're feeling romantic.\n",
            "If he seems shocked or pulls away, you may want to slow things down a bit.\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\ttry tongue-kissing if it's clear he wants to take things up a notch\n",
            "\task if you can kiss him if you aren't sure\n",
            "\tleave him wanting more\n",
            ">try tongue-kissing and take things up a notch\n",
            "That could work in an ideal world, but that is not what we have here. Try again please!\n",
            ">ask if you can kiss him\n",
            "This might sound awkward, but it can actually be a sweet, cute moment! It also gives him a little warning that it's about to happen, and you'll avoid a blatant rejection if he's not into it.\n",
            "You try something like, “I've had such a fun day and I'd really like to kiss you right now.\n",
            "You would that be okay?” Or, if you're feeling bolder, you can always go with, \"Wanna make out?”\n",
            "Boundaries are really important, so if you aren't sure, just ask\".\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\tlean in, close your eyes, and tilt your head to the side\n",
            "\texplain your preferences to him in a gentle way\n",
            "\tleave him wanting more\n",
            ">lean in, close your eyes, and tilt your head to the side\n",
            "You don't have to close your eyes, but it could be pretty awkward or distracting to stare at him the whole time! It's best to just keep them closed.\n",
            "Also, right before you lock lips, tilt your head to the side a bit.\n",
            "You tip: Kissing is easier if one person's mouth is tilted significantly sideways.\n",
            "Plus, it prevents your noses and teeth from bumping!.\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\ttouch your lips to his lightly and softly at first\n",
            "\tleave him wanting more\n",
            "\tkeep your body language positive and open\n",
            ">touch your lips to his lightly and softly at first\n",
            "When you first make contact, lightly graze your lips over his.\n",
            "You try to keep your pressure light and your movements slow and gentle.\n",
            "You keep your mouth closed for now.\n",
            "If it seems like he's enjoying it, you can ramp things up a bit.\n",
            "You avoid putting your lips into a tight pucker, which may indicate that you're not that into the moment.\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\texplore other ways to kiss him\n",
            "\tleave him wanting more\n",
            "\tgo in for a hug or snuggle to initiate a romantic moment\n",
            ">leave him wanting more\n",
            "Whoa! You should not do that yet.\n",
            ">explore other ways to kiss him\n",
            "Kisses don't always have to be on the lips! Give your mouths a break and try kissing him on the earlobe, under the jawbone, or on the inside of his wrist.\n",
            "If you want to take it up a notch, try kissing him in the little hollow place near his collarbone.\n",
            "You can also catch your breath by giving him sweet pecks on the nose or forehead.\n",
            "Don't try to rush things! Move at a pace that's comfortable for both of you.\n",
            "\n",
            "What do you do next?\n",
            "You:\n",
            "\tuse your tongue sparingly\n",
            "\tfind excuses to touch him in small, fleeting ways\n",
            "\ttry tongue-kissing if it's clear he wants to take things up a notch\n",
            ">use your tongue sparingly\n",
            "That could work in an ideal world, but that is not what we have here. Try again please!\n",
            ">quit\n",
            "You ended the game.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}