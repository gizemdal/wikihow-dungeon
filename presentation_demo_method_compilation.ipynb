{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "presentation_demo_method_compilation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V00oq1Gijyfp",
        "colab_type": "text"
      },
      "source": [
        "Add necessary imports here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0bjJ3ameX5",
        "colab_type": "code",
        "outputId": "94935f70-f5e5-45fc-a518-0a6f69b474ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip3 install pymagnitude\n",
        "!wget http://magnitude.plasticity.ai/glove/heavy/glove.6B.300d.magnitude\n",
        "\n",
        "from pymagnitude import *\n",
        "vectors = Magnitude(\"glove.6B.300d.magnitude\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymagnitude in /usr/local/lib/python3.6/dist-packages (0.1.120)\n",
            "--2020-04-22 02:50:39--  http://magnitude.plasticity.ai/glove/heavy/glove.6B.300d.magnitude\n",
            "Resolving magnitude.plasticity.ai (magnitude.plasticity.ai)... 52.217.9.227\n",
            "Connecting to magnitude.plasticity.ai (magnitude.plasticity.ai)|52.217.9.227|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1384890368 (1.3G) [binary/octet-stream]\n",
            "Saving to: ‘glove.6B.300d.magnitude’\n",
            "\n",
            "glove.6B.300d.magni 100%[===================>]   1.29G  52.4MB/s    in 24s     \n",
            "\n",
            "2020-04-22 02:51:04 (54.0 MB/s) - ‘glove.6B.300d.magnitude’ saved [1384890368/1384890368]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxqw4tkIjdZm",
        "colab_type": "code",
        "outputId": "f2aa99c1-ff18-4f58-effd-b77322110232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import string\n",
        "import nltk, string, os, json\n",
        "\n",
        "from nltk import RegexpParser\n",
        "from nltk.tree import Tree\n",
        "import random\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7n_dq__imjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "badc9f8a-ab8e-4de8-f76d-5f05490b83db"
      },
      "source": [
        "!mkdir encoder\n",
        "!curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘encoder’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0  21.4M      0  0:00:06  0:00:06 --:--:-- 25.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw2yupugm-xc",
        "colab_type": "text"
      },
      "source": [
        "Set up models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WslCK9eniuYl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "e37badd6-fb58-4c1e-feb2-412d517b719a"
      },
      "source": [
        "# Include models.py in the directory\n",
        "files.upload()\n",
        "from models import InferSent\n",
        "model_version = 1\n",
        "MODEL_PATH = \"encoder/infersent%s.pkl\" % model_version\n",
        "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
        "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
        "model = InferSent(params_model)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-217ef50f-dc1e-473e-ad63-66c6702bfc36\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-217ef50f-dc1e-473e-ad63-66c6702bfc36\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving models.py to models.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3IJTj70kZzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.set_w2v_path('drive/Shared drives/CIS 700 Project/GloVe/glove.840B.300d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuMzIoOYkc6R",
        "colab_type": "code",
        "outputId": "bef76282-94c6-479f-b19b-38f730a8e31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.build_vocab_k_words(K=100000)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnhRWtBnC-K",
        "colab_type": "text"
      },
      "source": [
        "Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5O17vcjlNY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59BNuFhsll1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_command(user_command, known_commands):\n",
        "\n",
        "  sim1 = find_most_similar_command(user_command, known_commands)\n",
        "  sim = []\n",
        "  for k in known_commands:\n",
        "    sim.append(cosine(model.encode(user_command)[0], model.encode(k)[0]))\n",
        "  # sim = [float(i)/sum(sim) for i in sim]\n",
        "  for i in range(len(sim)):\n",
        "    sim[i] += sim1[i]\n",
        "  idx = sim.index(max(sim))\n",
        "  #print(sim)\n",
        "  #print(idx)\n",
        "  return known_commands[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oZ7xehPlmKN",
        "colab_type": "text"
      },
      "source": [
        "Add necessary dictionaries/lists and parsing methods here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGn2MLXhljpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_article(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        s = [] # steps - list of tuples (method_number, step text)\n",
        "        d = {} # descriptions - Description dictionary step text -> description\n",
        "        m = [] # methods\n",
        "        data_json = json.load(f)\n",
        "        title = data_json['title']\n",
        "        if title != None:\n",
        "        # Get the steps\n",
        "            if len(data_json['method/part']) > 0:\n",
        "                methods = data_json['method/part']\n",
        "                for method in methods:\n",
        "                    all_steps = [(method['name'], step['headline']) for step in method['steps']]\n",
        "                    s += all_steps\n",
        "                    m += method['name']\n",
        "                    all_descs = dict(zip([step['headline'] for step in method['steps']], [step['description'] for step in method['steps']]))\n",
        "                    d.update(all_descs)      \n",
        "            else:\n",
        "              print(filename)\n",
        "               # s = [(None, step[0]) for step in data_json['steps']]\n",
        "               # d = dict(zip([step[0] for step in data_json['steps']], [step[1] for step in data_json['steps']]))\n",
        "        else:\n",
        "            print('Article has no title!')\n",
        "        return s, d, m, title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycT2eU3SnKJy",
        "colab_type": "text"
      },
      "source": [
        "NLTK Package Downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0xYG8mDXoN",
        "colab_type": "code",
        "outputId": "1b3787f8-dbfc-4ed2-8a34-9f37449794fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# download averaged_perceptron_tagger, wordnet\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tLcCfm4l-A-",
        "colab_type": "text"
      },
      "source": [
        "Add NLTK POS-tagging and tokenizer here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_CsP9T2mDP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source: https://stackoverflow.com/questions/29473169/approach-for-identifying-whether-a-sentence-includes-an-imperative-within-it?fbclid=IwAR1kGWHvo0M1sSMMXl4Rv4PJ-dhRchEABc83JQpAqotQnFqY3uUBD0jAMAU\n",
        "\n",
        "def is_imperative(tagged_sent):\n",
        "    # if the sentence is not a question...\n",
        "    if tagged_sent[-1][0] != \"?\":\n",
        "         #catches simple imperatives, e.g. \"Open the pod bay doors, HAL!\"\n",
        "        \n",
        "        if tagged_sent[0][1] == \"VB\" or tagged_sent[0][1] == \"MD\":\n",
        "            return True\n",
        "        \n",
        "        # catches imperative sentences starting with words like 'please', 'you',...\n",
        "        # E.g. \"Dave, stop.\", \"Just take a stress pill and think things over.\"\n",
        "        else:\n",
        "          # check if the first word has a verb synonym\n",
        "          synonyms = [syns.name() for syns in wordnet.synsets(tagged_sent[0][0])]\n",
        "          # split the synonyms array into two: more related synonyms should appear earlier\n",
        "          # Follow a heuristic such that if a verb synonym doesn't appear in the first half\n",
        "          # then this word is likely more often used as a noun\n",
        "          synonyms = synonyms[0:len(synonyms)//2]\n",
        "          for synonym in synonyms:\n",
        "            # if there is a verb written the same way as the first token, return true\n",
        "            splitted = synonym.split('.')\n",
        "            if splitted[1] == 'v':\n",
        "              if splitted[0] == tagged_sent[0][0].lower():\n",
        "                return True\n",
        "          #chunk = get_chunks(tagged_sent)\n",
        "          # check if the first chunk of the sentence is a VB-Phrase\n",
        "          #if type(chunk[0]) is Tree and chunk[0].label() == \"VB-Phrase\":\n",
        "              #return True\n",
        "    # For the sake of our game, consider the questions as non-imperative  \n",
        "    return False\n",
        "\n",
        "# chunks the sentence into grammatical phrases based on its POS-tags\n",
        "def get_chunks(tagged_sent):\n",
        "    chunkgram = r\"\"\"VB-Phrase: {<DT><,>*<VB>}\n",
        "                    VB-Phrase: {<RB><VB>}\n",
        "                    VB-Phrase: {<UH><,>*<VB>}\n",
        "                    VB-Phrase: {<UH><,><VBP>}\n",
        "                    VB-Phrase: {<PRP><VB>}\n",
        "                    VB-Phrase: {<NN.?>+<,>*<VB>}\n",
        "                    Q-Tag: {<,><MD><RB>*<PRP><.>*}\"\"\"\n",
        "    chunkparser = RegexpParser(chunkgram)\n",
        "    return chunkparser.parse(tagged_sent)\n",
        "\n",
        "# Tokenizer that I implemented from CIS421\n",
        "def tokenize(text):\n",
        "    tokens = []\n",
        "    words = text.split(' ')\n",
        "    for word in words:\n",
        "        if len(word) == 0:\n",
        "            continue\n",
        "        w = []\n",
        "        for c in word:\n",
        "            if c in string.punctuation:\n",
        "              if c == '\\'':\n",
        "                w.append(c)\n",
        "              else:\n",
        "                  if len(w) != 0:\n",
        "                      tokens.append(''.join(w))\n",
        "                      w = []\n",
        "                  tokens.append(c)\n",
        "            else:\n",
        "                if c not in string.whitespace:\n",
        "                    w.append(c)\n",
        "        if len(w) != 0:\n",
        "            tokens.append(''.join(w))\n",
        "    return tokens\n",
        "\n",
        "def imperative_check(text):\n",
        "  # First tokenize the step headline\n",
        "  tokens = tokenize(text)\n",
        "  # Get the POS-tags\n",
        "  tags = nltk.pos_tag(tokens)\n",
        "  # Check if imperative\n",
        "  imperative = is_imperative(tags)\n",
        "  \n",
        "  return imperative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkblXFACmbI-",
        "colab_type": "text"
      },
      "source": [
        "Add similarity check functions here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaGYou_ums8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get vector for the given sentence\n",
        "def construct_sentence_vector(command, vectors):\n",
        "  sentence_vector = np.zeros(shape=(vectors.dim,))\n",
        "  for word in command.split():\n",
        "    word_vector = vectors.query(word)\n",
        "    sentence_vector += word_vector\n",
        "  sentence_vector = sentence_vector / len(command.split())\n",
        "  return sentence_vector\n",
        "\n",
        "def construct_sentence_vector(command):\n",
        "  sentence_vector = np.zeros(shape=(vectors.dim,))\n",
        "  cnt = 0\n",
        "  for word in command.split():\n",
        "    word_vector = vectors.query(word)\n",
        "    # TODO - Do something\n",
        "    sentence_vector = sentence_vector + word_vector\n",
        "    cnt+=1\n",
        "  sentence_vector = sentence_vector/cnt\n",
        "  return sentence_vector\n",
        "\n",
        "#compare items in the list to the article_field. for instance, if you want to find the most similar titles\n",
        "#article_field should be the title, and list should be a list of titles you want to find the most similar out of\n",
        "def find_most_similar(article_field, list, vectors):\n",
        "  vecs = {}\n",
        "  max_sim = 0\n",
        "  most_sim = list[0]\n",
        "  vector_1 = construct_sentence_vector(article_field, vectors)\n",
        "  for obj in list:\n",
        "    vecs[obj] = construct_sentence_vector(obj, vectors)\n",
        "  for obj in vecs:\n",
        "    sim = vectors.similarity(vecs[obj], vector_1)\n",
        "    if sim > max_sim:\n",
        "      most_sim = obj\n",
        "      max_sim = sim\n",
        "  return most_sim\n",
        "\n",
        "def find_most_similar_command(user_command, known_commands):\n",
        "  # TODO - Do something\n",
        "  user_sent = construct_sentence_vector(user_command)\n",
        "  known_sent = []\n",
        "  for command in known_commands:\n",
        "    known_sent.append(construct_sentence_vector(command))\n",
        "  #ans = vectors.similarity(user_sent, known_sent) \n",
        "  known_sent = np.array(known_sent)\n",
        "  sim = vectors.similarity(user_sent, known_sent).tolist()\n",
        "  # ind = sim.index(max(sim))\n",
        "  # print(sim)\n",
        "  # return known_commands[ind]\n",
        "  return sim\n",
        "\n",
        "#get the top k most similar\n",
        "def top_k_similar(article_field, list, vectors, k):\n",
        "  top = []\n",
        "  for i in range(k):\n",
        "    most_sim = find_most_similar(article_field, list, vectors)\n",
        "    top.append(most_sim)\n",
        "    list.remove(most_sim)\n",
        "  return top\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp_ODobWo8FN",
        "colab_type": "text"
      },
      "source": [
        "Add object identifier & 3rd person sentence formation here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADEpXL8QpB4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# refered from https://stackoverflow.com/questions/41051125/turning-a-sentence-from-first-to-second-person\n",
        "\n",
        "forms = {\"am\" : \"are\", \"are\" : \"am\", 'i' : 'you', 'my' : 'your', 'me' : 'you', 'mine' : 'yours', 'you' : 'I', \n",
        "'your' : 'my', 'yours' : 'mine'}\n",
        "\n",
        "def translate(text):\n",
        "  # print(text)\n",
        "  result = text\n",
        "  for word in text.split():\n",
        "    # print(word)\n",
        "    if word.lower() in forms: \n",
        "      result = result.replace(word, forms[word.lower()])\n",
        "      # print(result)\n",
        "  # print(result)\n",
        "  return result\n",
        "\n",
        "def changePerson(text):\n",
        "  result = \"\"\n",
        "  tags = nltk.pos_tag(tokenize(text))\n",
        "  isImp = is_imperative(tags)\n",
        "\n",
        "  if isImp:\n",
        "    if text[0] == ' ' or text[0] == '\\n':\n",
        "      result = \"You \" + text[1].lower() + text[2:]\n",
        "    else:\n",
        "      result = \"You \" + text[0].lower() + text[1:]\n",
        "  else:\n",
        "    result = translate(text)\n",
        "  return result\n",
        "\n",
        "def identifyObjects(text):\n",
        "  tags = nltk.pos_tag(tokenize(text))\n",
        "  objects = []\n",
        "  for t in tags:\n",
        "    if t[1]==\"NN\":\n",
        "      objects.append(t[0])\n",
        "  return objects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVlVmf0lnWN7",
        "colab_type": "text"
      },
      "source": [
        "Description Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZVx1m7mN6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_description(title):\n",
        "  DATA = \"\"\n",
        "  tit=\"\"\n",
        "  if title.split()[0].lower()==\"how\" and title.split()[1].lower()==\"to\":\n",
        "    tit += \"You want \"\n",
        "    tit += \" \".join(title.split()[1:])\n",
        "  # else:\n",
        "  \n",
        "\n",
        "  objects = identifyObjects(title)\n",
        "  if len(objects) == 0:\n",
        "    DATA = tit\n",
        "  else:\n",
        "    DATA += (tit + '\\n')\n",
        "  # print(objects)\n",
        "  if len(objects)==1:\n",
        "    s = \"You have a \" + objects[0] + \"\\n\"\n",
        "    DATA += s\n",
        "  elif len(objects)>1:\n",
        "    ob = ''\n",
        "    ob += ', '.join(objects)\n",
        "    s = \"You have \" + ob + '\\n'\n",
        "    DATA += s\n",
        "  \n",
        "  print(DATA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emb5e4PbkgAq",
        "colab_type": "text"
      },
      "source": [
        "Once imports and functions are done, upload a JSON file, get its name and parse it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrx0bPyhkls_",
        "colab_type": "code",
        "outputId": "99791b23-92d1-4fc2-dd4b-55e86b8c9110",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8cde5cc8-21c2-4036-b61a-bb295a5d7db3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8cde5cc8-21c2-4036-b61a-bb295a5d7db3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 4027.json to 4027.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QHzl_kv-htb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d4a5987-06ba-4d1f-ff4b-0b6f9b560f45"
      },
      "source": [
        "try:\n",
        "  file_name = list(uploaded.keys())[0]\n",
        "  print(file_name)\n",
        "except:\n",
        "  f = open('/content/3029.json')\n",
        "  file_name = f.name.split('/')\n",
        "  file_name = file_name[len(file_name) - 1]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4027.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp1JD5snlA01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trim_beginning_punctuation(sentence):\n",
        "  to_return = ''\n",
        "  letter_seen = False\n",
        "  for c in sentence:\n",
        "    if c in string.punctuation or c in string.whitespace:\n",
        "      if letter_seen:\n",
        "        to_return += c\n",
        "    else:\n",
        "      if c in string.ascii_letters:\n",
        "        if not letter_seen:\n",
        "          letter_seen = True\n",
        "        to_return += c\n",
        "  return to_return\n",
        "\n",
        "def milestone_1_results(filename, include_desc):\n",
        "  # include_desc -> Do you want to include imperative description sentences as game steps?\n",
        "  steps, descriptions, method_names, title = get_article(filename)\n",
        "  # print the title of the article\n",
        "  #print('Title: ' + title)\n",
        "  print(title)\n",
        "  # Once the necessary fields are filled, find imperatives\n",
        "  imperatives = []\n",
        "\n",
        "  for step in steps:\n",
        "    # First split the headline into sentences\n",
        "    headline_sentences = step[1].split('.')\n",
        "    for headline in headline_sentences:\n",
        "      trimmed_headline = trim_beginning_punctuation(headline)\n",
        "      trimmed_headline = trimmed_headline.replace('\\n', '')\n",
        "      if len(trimmed_headline) == 0:\n",
        "          continue\n",
        "      if imperative_check(trimmed_headline):\n",
        "        imperatives.append(trimmed_headline)\n",
        "        break # No two imperatives from the same headline are added.\n",
        "    if include_desc:\n",
        "      description = descriptions[step[1]]\n",
        "      # Split the description paragraph into sentences\n",
        "      sentences = description.split('.')\n",
        "      for sentence in sentences:\n",
        "        trimmed_sentence = trim_beginning_punctuation(sentence)\n",
        "        trimmed_sentence = trimmed_sentence.replace('\\n', '')\n",
        "        if len(trimmed_sentence) == 0:\n",
        "          continue\n",
        "        if imperative_check(trimmed_sentence):\n",
        "          imperatives.append(trimmed_sentence)\n",
        "          break # No two imperatives from the same description are added. !!! REMOVE THIS IF you want multiple imperatives\n",
        "\n",
        "    \n",
        "  # Once imperatives are found, print them and turn them into 3rd person\n",
        "  #print('\\nList of Imperatives:\\n')\n",
        "  #for imp in imperatives:\n",
        "    #print(imp)\n",
        "    \n",
        "  third_person = [changePerson(imperative) for imperative in imperatives]\n",
        "  return third_person, title\n",
        "\n",
        "  # Print the 3rd person sentences in order\n",
        "  #print('\\nImperatives Turned Into 3rd Person:\\n')\n",
        "  #for third in third_person:\n",
        "    #print(third)\n",
        "  \n",
        "  # # Find 5 similar articles to this article given the title\n",
        "  # k = 5\n",
        "\n",
        "  # # Make sure that the folder new_wikihow_1000 is in the drive - that's where we have all the data\n",
        "  # file_path = '/content/drive/My Drive/Colab Notebooks/new_wikihow_1000'\n",
        "  # all_files = os.listdir(file_path)\n",
        "  # files_and_titles = {} # title -> filename dictionary\n",
        "  # idx = 0\n",
        "  # for data in all_files:\n",
        "  #   if idx >= 100: # for now the number of files to read is limited to 100\n",
        "  #     break\n",
        "  #   with open(file_path + '/' + data, \"r\") as f:\n",
        "  #     data_json = json.load(f)\n",
        "  #     t = data_json['title']\n",
        "  #     # Skip articles with no title\n",
        "  #     if t == None:\n",
        "  #       continue\n",
        "  #     files_and_titles[t] = data\n",
        "  #     idx += 1\n",
        "  \n",
        "  # # Once we have file titles, pass them as a list to top_k_similar()\n",
        "  # k_similar = top_k_similar(title, list(files_and_titles.keys()), vectors, k)\n",
        "  \n",
        "  # # Print the top k similar article titles and the corresponding json file name\n",
        "  # print('\\nTop ' + str(k) + ' Similar Article Titles:\\n')\n",
        "  # for similar in k_similar:\n",
        "  #   print('Title: ' + similar + ', Filename: ' + files_and_titles[similar])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIAWaWnUnmbz",
        "colab_type": "text"
      },
      "source": [
        "Start extracting from article here:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt2m3sCSnmEB",
        "colab_type": "code",
        "outputId": "aa855623-0d6f-4ee2-df2d-294e08826592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Send True to include descriptions as well!\n",
        "known_commands, title = milestone_1_results(file_name, False)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How to Make a Beaded Necklace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZjDqIVdkje_",
        "colab_type": "code",
        "outputId": "9dfdce8f-ffc6-4920-d770-89a4110a34b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "try:\n",
        "  embeddings = model.encode(known_commands, bsize=128, tokenize=False, verbose=True)\n",
        "  print('nb sentences encoded : {0}'.format(len(embeddings)))\n",
        "except:\n",
        "  print('This article has no imperatives!')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb words kept : 103/109 (94.5%)\n",
            "Speed : 22.0 sentences/s (cpu mode, bsize=128)\n",
            "nb sentences encoded : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfUpGmwxrex5",
        "colab_type": "text"
      },
      "source": [
        "Method for choice picking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RiMu5X2rdxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pick_choices(current_step, commands):\n",
        "  if len(commands) - 1 == current_step:\n",
        "    return None, None\n",
        "  elif len(commands) - 2 == current_step:\n",
        "    # Can only pick one wrong choice\n",
        "    return len(commands) - 1, None\n",
        "  else:\n",
        "    # pick 2 that are not in steps_seen\n",
        "    options_first = [num for num in range(current_step + 1, len(commands))]\n",
        "    first = random.choice(options_first)\n",
        "    options_second = [num for num in range(current_step + 1, len(commands)) if num != first]\n",
        "    second = random.choice(options_second)\n",
        "    return first,second"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrVRSszjpS_R",
        "colab_type": "text"
      },
      "source": [
        "Start the game here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIPXouHvpZaC",
        "colab_type": "code",
        "outputId": "57d17961-bb27-4ee6-d6ca-1f0dbbc7b1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "current_step = 0\n",
        "steps_seen = []\n",
        "end_game = False\n",
        "get_description(title)\n",
        "while not end_game:\n",
        "  if current_step == len(known_commands):\n",
        "    end_game = True\n",
        "    print('You reached the end of the game')\n",
        "  else:\n",
        "    current_step_text = known_commands[current_step]\n",
        "    # get the description of current step text\n",
        "    get_description(current_step_text)\n",
        "    print('What do you do?')\n",
        "    print('You:')\n",
        "    first, second = pick_choices(current_step, known_commands)\n",
        "    choices = []\n",
        "    # if wrong choices exist\n",
        "    if first:\n",
        "      if second:\n",
        "        choices.append(known_commands[second])\n",
        "      choices.append(known_commands[first])\n",
        "    choices.append(known_commands[current_step])\n",
        "    correct_choice = known_commands[current_step] # this is the correct choice\n",
        "    random.shuffle(choices) # shuffle the order of choices\n",
        "    for choice in choices:\n",
        "      print('\\t' + choice[4:])\n",
        "    correct_found = False\n",
        "    while not correct_found:\n",
        "      user_pick = input('>')\n",
        "      if user_pick.lower() == 'quit':\n",
        "        correct_found = True\n",
        "        end_game = True\n",
        "        print('You ended the game.')\n",
        "        continue\n",
        "      # Check if what the user picked is correct\n",
        "      most_similar = find_similar_command(user_pick, known_commands)\n",
        "      if most_similar[4:].lower() == correct_choice[4:].lower():\n",
        "        # Correct!\n",
        "        current_step += 1\n",
        "        correct_found = True\n",
        "      else:\n",
        "        print('Try again.')\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You want to Make a Beaded Necklace\n",
            "You have a Necklace\n",
            "\n",
            "\n",
            "You have a beading\n",
            "\n",
            "What do you do?\n",
            "You:\n",
            "\tgather  crimp beads,  clasp, and the beads for the desired necklace\n",
            "\tgather your beading materials\n",
            "\tthread the end of the stringing material through the clasp section\n",
            ">gather beading materials\n",
            "\n",
            "You have necklace, style\n",
            "\n",
            "What do you do?\n",
            "You:\n",
            "\tselect a length\n",
            "\tplace your bead board on your flat surface\n",
            "\tdetermine your necklace style\n",
            ">determine your necklace style\n",
            "\n",
            "You have a length\n",
            "\n",
            "What do you do?\n",
            "You:\n",
            "\tuse a clasp section\\/ jump ring and the bead-crimp-bead combo\n",
            "\tarrange your beads on a flat surface, like a table or a desk\n",
            "\tselect a length\n",
            ">quit\n",
            "You ended the game.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}